{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1kcBRQRqg3ZlTKwV2jdZoX3Id_EHg_ffc",
      "authorship_tag": "ABX9TyNGi1wJLXStaKzVODVgsFvq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RolakeOkans/pembrolizumab-hcc-response-modeling/blob/main/HPC_dataset_updated_11_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywXp8Cku_LWT",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install adjustText"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Response Data:From GSE242154.txt file, extract info for each sample and put into a dataframe\n",
        "#This will enable me to see each sample, tissue type, roi, biomarker, response etc\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from adjustText import adjust_text\n",
        "import numpy as np\n",
        "\n",
        "samples = []\n",
        "current_sample = {}\n",
        "\n",
        "with open('/content/GSE242154.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line.startswith('^SAMPLE'):\n",
        "            if current_sample:\n",
        "                samples.append(current_sample)\n",
        "            current_sample = {'Sample_ID': line.split('=')[1].strip(),\n",
        "                              'Sample_title': '',\n",
        "                              'Sample_geo_accession': ''}\n",
        "        elif line.startswith('!Sample_title'):\n",
        "            current_sample['Sample_title'] = line.split('=')[1].strip()\n",
        "        elif line.startswith('!Sample_geo_accession'):\n",
        "            current_sample['Sample_geo_accession'] = line.split('=')[1].strip()\n",
        "        elif line.startswith('!Sample_characteristics_ch1'):\n",
        "            # split by first colon to get key/value\n",
        "            key_value = line.split('=')[1].strip().split(':', 1)\n",
        "            if len(key_value) == 2:\n",
        "                key = key_value[0].strip().replace(\" \", \"_\")  # replace spaces with _\n",
        "                value = key_value[1].strip()\n",
        "                current_sample[key] = value\n",
        "\n",
        "# Add last sample\n",
        "if current_sample:\n",
        "    samples.append(current_sample)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(samples)\n",
        "\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('samples_characteristics.csv', index=False)\n"
      ],
      "metadata": {
        "id": "2V7wAJdn_Rde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gene Expression Data: From GEO series_matrix files, get gene expression data for each sample\n",
        "file_path = '/content/GSE242154_series_matrix.txt'\n",
        "gene_exp_df = pd.read_csv(file_path, sep='\\t', header=None, comment='!')  # ignore comment lines starting with !\n",
        "\n",
        "# 2. Peek at the first few rows\n",
        "print(gene_exp_df.head())\n",
        "\n",
        "# 3. Get all column names (if they exist)\n",
        "print(\"Columns:\", gene_exp_df.columns.tolist())\n",
        "\n",
        "# 4. If the first row contains the column names, reload with header\n",
        "gene_exp_df = pd.read_csv(file_path, sep='\\t', header=0, comment='!')\n",
        "print(\"Columns now:\", gene_exp_df.columns.tolist())\n",
        "\n",
        "# 5. Optional: see number of rows and columns\n",
        "print(\"Shape:\", gene_exp_df.shape)"
      ],
      "metadata": {
        "id": "O6Vh3tOB_VDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combine Response Data with Gene Expression Data\n",
        "\n",
        "# Load metadata\n",
        "metadata_df = pd.read_csv('samples_characteristics.csv')\n",
        "\n",
        "# Check metadata sample IDs\n",
        "print(metadata_df['Sample_ID'].head())\n",
        "\n",
        "# Load expression data (series matrix), assuming first column = Protein, rest = samples\n",
        "expr_file = '/content/GSE242154_series_matrix.txt'\n",
        "\n",
        "# Read expression manually because comment lines interfere\n",
        "expr_lines = []\n",
        "with open(expr_file, 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line or line.startswith('!') or line.startswith('^'):\n",
        "            continue\n",
        "        expr_lines.append(line.split('\\t'))\n",
        "\n",
        "# First column = protein names\n",
        "protein_names = [row[0] for row in expr_lines]\n",
        "sample_values = [row[1:] for row in expr_lines]\n",
        "\n",
        "# Samples in the same order as they appear in the file\n",
        "sample_ids = [col.strip() for col in expr_lines[0][1:]]\n",
        "\n",
        "# Create expression DataFrame\n",
        "expr_df = pd.DataFrame(sample_values, columns=metadata_df['Sample_ID'], index=protein_names).T\n",
        "expr_df.index.name = 'Sample_ID'\n",
        "\n",
        "# Merge metadata with expression data\n",
        "combined_df = expr_df.merge(metadata_df, on='Sample_ID', how='left')\n",
        "\n",
        "# Save final combined table\n",
        "combined_df.to_csv('combined_expression_metadata.csv')\n",
        "\n",
        "print(\"Combined shape:\", combined_df.shape)\n",
        "print(combined_df.head())\n"
      ],
      "metadata": {
        "id": "TWmdNiNf_Xk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# STEP 4: Quality Control Checks\n",
        "# -------------------------------\n",
        "\n",
        "print(\"\\n===== QC CHECKS =====\")\n",
        "\n",
        "#Metadata integrity\n",
        "print(\"\\n--- Missing values per column ---\")\n",
        "print(combined_df.isnull().sum())\n",
        "\n",
        "print(\"\\n--- Unique Sample IDs ---\")\n",
        "print(\"Unique IDs:\", combined_df['Sample_ID'].nunique())\n",
        "print(\"Total rows:\", combined_df.shape[0])\n",
        "\n",
        "# Count samples per metadata category (if present)\n",
        "for col in ['tissue_type', 'roi', 'biomarker', 'response']:\n",
        "    if col in combined_df.columns:\n",
        "        print(f\"\\n--- Counts for {col} ---\")\n",
        "        print(combined_df[col].value_counts())"
      ],
      "metadata": {
        "id": "sZH1VjOW_Yb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize protein expression using quantile normalization\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 1: Load combined data\n",
        "# -------------------------------\n",
        "combined_df = pd.read_csv(\"combined_expression_metadata.csv\")\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 2: Clean column names\n",
        "# -------------------------------\n",
        "combined_df.columns = [c.strip().replace('\"','') for c in combined_df.columns]\n",
        "\n",
        "# Explicit metadata columns (these will not be normalized)\n",
        "metadata_cols = [\n",
        "    'Sample_ID','Sample_title','Sample_geo_accession','tissue_type',\n",
        "    'region_of_interest_(roi)_number','segment_type',\n",
        "    'positive_immuno-fluorescent_morphology_marker',\n",
        "    'radiographic_objective_response'\n",
        "]\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 3: Define proteins to normalize\n",
        "# -------------------------------\n",
        "proteins_to_normalize = [\n",
        "    \"4-1BB\",\"ARG1\",\"B7-H3\",\"Bcl-2\",\"Beta-2-microglobulin\",\"CD11c\",\"CD127\",\n",
        "    \"CD14\",\"CD163\",\"CD20\",\"CD25\",\"CD27\",\"CD3\",\"CD34\",\"CD4\",\"CD40\",\"CD44\",\n",
        "    \"CD45\",\"CD45RO\",\"CD56\",\"CD66b\",\"CD68\",\"CD8\",\"CD80\",\"CTLA4\",\"EpCAM\",\n",
        "    \"ER-alpha\",\"FAP-alpha\",\"Fibronectin\",\"FOXP3\",\"GAPDH\",\"GITR\",\"GZMB\",\n",
        "    \"Her2\",\"Histone H3\",\"HLA-DR\",\"ICOS\",\"IDO1\",\"Ki-67\",\"LAG3\",\"MART1\",\n",
        "    \"Ms IgG1\",\"Ms IgG2a\",\"NY-ESO-1\",\"OX40L\",\"PanCk\",\"PD-1\",\"PD-L1\",\"PD-L2\",\n",
        "    \"PR\",\"PTEN\",\"Rb IgG\",\"S100B\",\"S6\",\"SMA\",\"STING\",\"Tim-3\",\"VISTA\"\n",
        "]\n",
        "\n",
        "# Clean protein names\n",
        "proteins_to_normalize = [p.strip().replace('\"','') for p in proteins_to_normalize]\n",
        "\n",
        "# Keep only proteins that exist in the dataset\n",
        "expr_cols = [c for c in proteins_to_normalize if c in combined_df.columns]\n",
        "print(\"Proteins to normalize found in dataset:\", expr_cols)\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 4: Extract protein expression data and ensure numeric\n",
        "# -------------------------------\n",
        "expr_df = combined_df[expr_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Check for all-NaN columns\n",
        "expr_df = expr_df.dropna(axis=1, how='all')\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 5: Quantile normalization\n",
        "# -------------------------------\n",
        "def quantile_normalize(df):\n",
        "    \"\"\"Perform quantile normalization on a DataFrame (samples x proteins).\"\"\"\n",
        "    # rank the values\n",
        "    sorted_df = np.sort(df.values, axis=0)\n",
        "    # compute row-wise mean\n",
        "    mean_ranks = np.mean(sorted_df, axis=1)\n",
        "    # get the ranks for each column\n",
        "    ranks = df.stack().groupby(df.rank(method='first').stack().astype(int)).mean()\n",
        "    # map ranks to mean values\n",
        "    rank_index = df.rank(method='min').stack().astype(int)\n",
        "    normalized_values = rank_index.map(lambda x: mean_ranks[x-1])\n",
        "    normalized_df = normalized_values.unstack()\n",
        "    return normalized_df\n",
        "\n",
        "expr_norm_df = quantile_normalize(expr_df)\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 6: Merge normalized proteins back with metadata\n",
        "# -------------------------------\n",
        "final_df = combined_df.copy()\n",
        "for col in expr_norm_df.columns:\n",
        "    final_df[col] = expr_norm_df[col]\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 7: Save final CSV\n",
        "# -------------------------------\n",
        "final_df.to_csv(\"combined_expression_metadata_quantile_normalized.csv\", index=False)\n",
        "print(\"✅ Quantile normalization completed and saved\")\n"
      ],
      "metadata": {
        "id": "guTP2A87_gHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look for differentially expressed proteins and visualize them using volcano plots\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from adjustText import adjust_text\n",
        "from scipy.stats import ttest_ind\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 1: Load normalized data\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"combined_expression_metadata_quantile_normalized.csv\")\n",
        "\n",
        "# Clean response column\n",
        "df['radiographic_objective_response'] = df['radiographic_objective_response'].astype(str).str.strip()\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 2: Define groups\n",
        "# -------------------------------\n",
        "responders = df[df['radiographic_objective_response'].isin(['complete response (CR)', 'partial response (PR)'])]\n",
        "non_responders = df[df['radiographic_objective_response'].isin(['progressive disease (PD)', 'stable disease (SD)'])]\n",
        "\n",
        "# Metadata columns\n",
        "metadata_cols = [\n",
        "    'Unnamed: 0', 'Sample_ID', 'ID_REF', 'Sample_title', 'Sample_geo_accession',\n",
        "    'patient_id', 'tissue_type', 'region_of_interest_(roi)_number', 'segment_type',\n",
        "    'positive_immuno-fluorescent_morphology_marker', 'radiographic_objective_response'\n",
        "]\n",
        "protein_cols = [c for c in df.columns if c not in metadata_cols]\n",
        "\n",
        "# -------------------------------\n",
        "# OPTIONAL: Top 15 proteins to label on volcano plots\n",
        "# IMPORTANT: These names must match exactly how they appear in results_df[\"Protein\"]\n",
        "# If your column names differ (e.g., \"HLA-DRA\" vs \"HLA-DR\"), edit accordingly.\n",
        "# -------------------------------\n",
        "top15_proteins = [\n",
        "    \"Her2\", \"MART1\", \"PTEN\", \"NY-ESO-1\", \"CD20\",\n",
        "    \"PR\", \"CD56\", \"HLA-DR\", \"S6\", \"ER-alpha\",\n",
        "    \"GAPDH\", \"IDO1\", \"PD-1\", \"GZMB\", \"LAG3\"\n",
        "]\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 3: Differential Expression\n",
        "# -------------------------------\n",
        "results = []\n",
        "for protein in protein_cols:\n",
        "    vals_resp = pd.to_numeric(responders[protein], errors='coerce').dropna()\n",
        "    vals_nonresp = pd.to_numeric(non_responders[protein], errors='coerce').dropna()\n",
        "\n",
        "    if len(vals_resp) < 2 or len(vals_nonresp) < 2:\n",
        "        continue\n",
        "\n",
        "    mean_resp = vals_resp.mean()\n",
        "    mean_nonresp = vals_nonresp.mean()\n",
        "\n",
        "    if mean_nonresp == 0:  # avoid division by zero\n",
        "        continue\n",
        "\n",
        "    fold_change = mean_resp / mean_nonresp\n",
        "    log2_fc = np.log2(fold_change)\n",
        "\n",
        "    t_stat, p_val = ttest_ind(vals_resp, vals_nonresp, equal_var=False)\n",
        "\n",
        "    results.append({\n",
        "        \"Protein\": protein,\n",
        "        \"Mean_Responders\": mean_resp,\n",
        "        \"Mean_NonResponders\": mean_nonresp,\n",
        "        \"FoldChange\": fold_change,\n",
        "        \"log2FC\": log2_fc,\n",
        "        \"p_value\": p_val\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Adjust p-values (FDR BH)\n",
        "results_df[\"adj_p_value\"] = multipletests(results_df[\"p_value\"], method=\"fdr_bh\")[1]\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 4: Test thresholds + Volcano plots\n",
        "# -------------------------------\n",
        "pval_thresh = 0.05\n",
        "fc_thresholds = {\n",
        "    \"2-fold\": 1.0,             # |log2FC| >= 1\n",
        "    \"1.5-fold\": np.log2(1.5),  # |log2FC| >= 0.585\n",
        "    \"1.2-fold\": np.log2(1.2)   # |log2FC| >= 0.263\n",
        "}\n",
        "\n",
        "summary = []\n",
        "\n",
        "for label, fc_thr in fc_thresholds.items():\n",
        "    # Subset DE proteins for this threshold\n",
        "    subset = results_df[\n",
        "        (results_df[\"adj_p_value\"] < pval_thresh) &\n",
        "        (abs(results_df[\"log2FC\"]) >= fc_thr)\n",
        "    ]\n",
        "    subset.to_csv(f\"DE_results_{label}_p0.05.csv\", index=False)\n",
        "\n",
        "    summary.append({\n",
        "        \"Threshold\": label,\n",
        "        \"log2FC_cutoff\": round(fc_thr, 3),\n",
        "        \"n_DE\": len(subset),\n",
        "        \"Up_in_Responders\": (subset[\"log2FC\"] > 0).sum(),\n",
        "        \"Up_in_NonResponders\": (subset[\"log2FC\"] < 0).sum()\n",
        "    })\n",
        "\n",
        "    # Mark significance (THIS IS YOUR ORIGINAL LOGIC)\n",
        "    results_df[\"Significant\"] = results_df.apply(\n",
        "        lambda r: \"Significant\"\n",
        "        if (r[\"adj_p_value\"] < pval_thresh and abs(r[\"log2FC\"]) >= fc_thr)\n",
        "        else \"Not significant\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Volcano plot\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    sns.scatterplot(\n",
        "        data=results_df,\n",
        "        x=\"log2FC\",\n",
        "        y=-np.log10(results_df[\"adj_p_value\"]),\n",
        "        hue=\"Significant\",\n",
        "        palette={\"Significant\": \"red\", \"Not significant\": \"grey\"},\n",
        "        legend=True\n",
        "    )\n",
        "    handles, labels = plt.gca().get_legend_handles_labels()\n",
        "    unique = dict(zip(labels, handles))\n",
        "    plt.legend(unique.values(), unique.keys(), title=\"Significance\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Threshold lines\n",
        "    plt.axhline(-np.log10(pval_thresh), color='black', linestyle='--')\n",
        "    plt.axvline(fc_thr, color='green', linestyle='--')\n",
        "    plt.axvline(-fc_thr, color='green', linestyle='--')\n",
        "\n",
        "    # -------------------------------\n",
        "    # LABEL TOP 15 PROTEINS (NO CHANGE TO SIGNIFICANCE)\n",
        "    # -------------------------------\n",
        "    texts = []\n",
        "    # Only label proteins that exist in results_df and are in your top15 list\n",
        "    label_df = results_df[results_df[\"Protein\"].isin(top15_proteins)].copy()\n",
        "\n",
        "    for _, row in label_df.iterrows():\n",
        "        texts.append(\n",
        "            plt.text(\n",
        "                row[\"log2FC\"],\n",
        "                -np.log10(row[\"adj_p_value\"]),\n",
        "                row[\"Protein\"],\n",
        "                fontsize=9\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Prevent label overlap\n",
        "    adjust_text(\n",
        "        texts,\n",
        "        arrowprops=dict(arrowstyle='-', color='black', lw=0.5)\n",
        "    )\n",
        "\n",
        "    plt.title(f\"Volcano Plot ({label} cutoff, adjusted p=0.05)\")\n",
        "    plt.xlabel(\"log2 Fold Change (Responder / Non-responder)\")\n",
        "    plt.ylabel(\"-log10(Adjusted p-value)\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"volcano_{label}_p0.05_top15_labeled.png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "# Save summary\n",
        "summary_df = pd.DataFrame(summary)\n",
        "summary_df.to_csv(\"DE_summary_all_thresholds.csv\", index=False)\n",
        "print(summary_df)\n",
        "\n",
        "# Optional sanity check: which of the top15 proteins were found in results_df?\n",
        "found = [p for p in top15_proteins if p in results_df[\"Protein\"].values]\n",
        "missing = [p for p in top15_proteins if p not in results_df[\"Protein\"].values]\n",
        "print(\"\\nTop15 proteins found in DE results:\", found)\n",
        "print(\"Top15 proteins missing (name mismatch?):\", missing)\n"
      ],
      "metadata": {
        "id": "75dK4cIDoLOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Look for differentially expressed genes and visualize them using volcano plots\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from adjustText import adjust_text\n",
        "from scipy.stats import ttest_ind\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 1: Load normalized data\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"combined_expression_metadata_quantile_normalized.csv\")\n",
        "\n",
        "# Clean response column\n",
        "df['radiographic_objective_response'] = df['radiographic_objective_response'].astype(str).str.strip()\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 2: Define groups\n",
        "# -------------------------------\n",
        "responders = df[df['radiographic_objective_response'].isin(['complete response (CR)', 'partial response (PR)'])]\n",
        "non_responders = df[df['radiographic_objective_response'].isin(['progressive disease (PD)', 'stable disease (SD)'])]\n",
        "\n",
        "# Metadata columns\n",
        "metadata_cols = [\n",
        "    'Unnamed: 0', 'Sample_ID', 'ID_REF', 'Sample_title', 'Sample_geo_accession',\n",
        "    'patient_id', 'tissue_type', 'region_of_interest_(roi)_number', 'segment_type',\n",
        "    'positive_immuno-fluorescent_morphology_marker', 'radiographic_objective_response'\n",
        "]\n",
        "protein_cols = [c for c in df.columns if c not in metadata_cols]\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 3: Differential Expression\n",
        "# -------------------------------\n",
        "results = []\n",
        "for protein in protein_cols:\n",
        "    vals_resp = pd.to_numeric(responders[protein], errors='coerce').dropna()\n",
        "    vals_nonresp = pd.to_numeric(non_responders[protein], errors='coerce').dropna()\n",
        "\n",
        "    if len(vals_resp) < 2 or len(vals_nonresp) < 2:\n",
        "        continue\n",
        "\n",
        "    mean_resp = vals_resp.mean()\n",
        "    mean_nonresp = vals_nonresp.mean()\n",
        "\n",
        "    if mean_nonresp == 0:  # avoid division by zero\n",
        "        continue\n",
        "\n",
        "    fold_change = mean_resp / mean_nonresp\n",
        "    log2_fc = np.log2(fold_change)\n",
        "\n",
        "    t_stat, p_val = ttest_ind(vals_resp, vals_nonresp, equal_var=False)\n",
        "\n",
        "    results.append({\n",
        "        \"Protein\": protein,\n",
        "        \"Mean_Responders\": mean_resp,\n",
        "        \"Mean_NonResponders\": mean_nonresp,\n",
        "        \"FoldChange\": fold_change,\n",
        "        \"log2FC\": log2_fc,\n",
        "        \"p_value\": p_val\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Adjust p-values (but p threshold remains fixed at 0.05)\n",
        "results_df[\"adj_p_value\"] = multipletests(results_df[\"p_value\"], method=\"fdr_bh\")[1]\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 4: Test thresholds\n",
        "# -------------------------------\n",
        "# Keep p=0.05 fixed\n",
        "pval_thresh = 0.05\n",
        "fc_thresholds = {\n",
        "    \"2-fold\" : 1.0,      # log2FC >= 1\n",
        "    \"1.5-fold\": np.log2(1.5),  # log2FC >= 0.585\n",
        "    \"1.2-fold\": np.log2(1.2)   # log2FC >= 0.263\n",
        "}\n",
        "\n",
        "summary = []\n",
        "\n",
        "for label, fc_thr in fc_thresholds.items():\n",
        "    subset = results_df[(results_df[\"adj_p_value\"] < pval_thresh) & (abs(results_df[\"log2FC\"]) >= fc_thr)]\n",
        "    subset.to_csv(f\"DE_results_{label}_p0.05.csv\", index=False)\n",
        "\n",
        "    summary.append({\n",
        "        \"Threshold\": label,\n",
        "        \"log2FC_cutoff\": round(fc_thr, 3),\n",
        "        \"n_DE\": len(subset),\n",
        "        \"Up_in_Responders\": (subset[\"log2FC\"] > 0).sum(),\n",
        "        \"Up_in_NonResponders\": (subset[\"log2FC\"] < 0).sum()\n",
        "    })\n",
        "\n",
        "    # Volcano plot for each threshold\n",
        "    results_df[\"Significant\"] = results_df.apply(\n",
        "        lambda r: \"Significant\" if (r[\"adj_p_value\"] < pval_thresh and abs(r[\"log2FC\"]) >= fc_thr)\n",
        "                  else \"Not significant\", axis=1\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(12,9))\n",
        "    sns.scatterplot(\n",
        "        data=results_df,\n",
        "        x=\"log2FC\", y=-np.log10(results_df[\"adj_p_value\"]),\n",
        "        hue=\"Significant\",\n",
        "        palette={\"Significant\":\"red\", \"Not significant\":\"grey\"},\n",
        "        legend=True\n",
        "    )\n",
        "\n",
        "    # threshold lines\n",
        "    plt.axhline(-np.log10(pval_thresh), color='black', linestyle='--')\n",
        "    plt.axvline(fc_thr, color='green', linestyle='--')\n",
        "    plt.axvline(-fc_thr, color='green', linestyle='--')\n",
        "\n",
        "    plt.title(f\"Volcano Plot ({label} cutoff, p=0.05)\")\n",
        "    plt.xlabel(\"log2 Fold Change (Responder / Non-responder)\")\n",
        "    plt.ylabel(\"-log10(Adjusted p-value)\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"volcano_{label}_p0.05.png\", dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "summary_df = pd.DataFrame(summary)\n",
        "summary_df.to_csv(\"DE_summary_all_thresholds.csv\", index=False)\n",
        "print(summary_df)\n"
      ],
      "metadata": {
        "id": "PmYTvZ46_haR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train a Random Forest Classifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, roc_curve, auc,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# LOAD DATA\n",
        "# ----------------------------------------------------------\n",
        "data = pd.read_csv(\"combined_expression_metadata_quantile_normalized.csv\")\n",
        "\n",
        "data['Response_Group'] = data['radiographic_objective_response'].replace({\n",
        "    'complete response (CR)': 1,\n",
        "    'partial response (PR)': 1,\n",
        "    'progressive disease (PD)': 0,\n",
        "    'stable disease (SD)': 0\n",
        "})\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# SELECT FEATURES / TARGET\n",
        "# ----------------------------------------------------------\n",
        "metadata_cols = [\n",
        "    'Unnamed: 0','Sample_ID','ID_REF','Sample_title','Sample_geo_accession',\n",
        "    'patient_id','tissue_type','region_of_interest_(roi)_number','segment_type',\n",
        "    'positive_immuno-fluorescent_morphology_marker',\n",
        "    'radiographic_objective_response','Response_Group'\n",
        "]\n",
        "\n",
        "X = data.drop(columns=metadata_cols)\n",
        "y = data['Response_Group']\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# TRAIN / TEST SPLIT\n",
        "# ----------------------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"TRAIN: {X_train.shape[0]}\")\n",
        "print(f\"TEST:  {X_test.shape[0]}\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# SCALE DATA\n",
        "# ----------------------------------------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# RANDOM FOREST (THE ONE THAT WORKED)\n",
        "# ----------------------------------------------------------\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=500,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_rf = rf.predict(X_test_scaled)\n",
        "y_prob_rf = rf.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# EVALUATION\n",
        "# ----------------------------------------------------------\n",
        "print(\"\\n===== RANDOM FOREST (ORIGINAL HIGH-SCORE MODEL) =====\")\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred_rf), 3))\n",
        "print(\"Precision:\", round(precision_score(y_test, y_pred_rf), 3))\n",
        "print(\"Recall:\", round(recall_score(y_test, y_pred_rf), 3))\n",
        "print(\"F1-score:\", round(f1_score(y_test, y_pred_rf), 3))\n",
        "print(\"ROC AUC:\", round(roc_auc_score(y_test, y_prob_rf), 3))\n",
        "\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "print(\"\\n--- Confusion Matrix ---\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# PLOT ROC\n",
        "# ----------------------------------------------------------\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
        "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.plot(fpr_rf, tpr_rf, color='blue', lw=2,\n",
        "         label=f'Random Forest (AUC = {roc_auc_rf:.2f})')\n",
        "plt.plot([0,1],[0,1],'--',color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - Random Forest (Original)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"RF_original_highscore.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# FEATURE IMPORTANCE\n",
        "# ----------------------------------------------------------\n",
        "rf_importance_df = pd.DataFrame({\n",
        "    'Protein': X.columns,\n",
        "    'Importance': rf.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 15 Important Proteins:\")\n",
        "print(rf_importance_df.head(15))\n",
        "\n",
        "rf_importance_df.to_csv(\"RF_feature_importance_original.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "IOeL4Y0bDUjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select top 15 proteins\n",
        "top15 = rf_importance_df.head(15)\n",
        "\n",
        "# Reverse order for horizontal bar plot (largest on top)\n",
        "top15 = top15.iloc[::-1]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.barh(top15['Protein'], top15['Importance'])\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Top 15 Proteins Contributing to Random Forest Predictions')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"RF_top15_feature_importance.png\", dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5FF66uYcHFKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hI7B1y8DGNai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------\n",
        "# PREDICTION SCORES FOR EACH PATIENT\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "# Probability that a sample is a responder (class = 1)\n",
        "prediction_scores = rf.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Convert to dataframe with IDs\n",
        "results_with_scores = pd.DataFrame({\n",
        "    \"Sample_ID\": X_test.index,\n",
        "    \"True_Label\": y_test.values,\n",
        "    \"Predicted_Label\": y_pred_rf,\n",
        "    \"Prediction_Score\": prediction_scores\n",
        "})\n",
        "\n",
        "# Sort by score (highest responders first)\n",
        "results_with_scores = results_with_scores.sort_values(by=\"Prediction_Score\", ascending=False)\n",
        "\n",
        "print(\"\\n===== PATIENT-LEVEL PREDICTION SCORES =====\")\n",
        "print(results_with_scores.head())\n",
        "\n",
        "# Save to CSV\n",
        "results_with_scores.to_csv(\"patient_prediction_scores_RF.csv\", index=False)\n",
        "print(\"\\nSaved → patient_prediction_scores_RF.csv\")\n"
      ],
      "metadata": {
        "id": "Pdb3hQyAaU1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# BUILD PREDICTION TABLE (DEFAULT 0.5)\n",
        "# ----------------------------------------------------------\n",
        "prediction_table = pd.DataFrame({\n",
        "    \"Sample_ID\": data.loc[y_test.index, \"Sample_ID\"].values,\n",
        "    \"True_Label\": y_test.values,\n",
        "    \"Predicted_Label\": y_pred_rf,\n",
        "    \"Prediction_Score\": np.round(y_prob_rf, 4)   # probability of being a responder\n",
        "})\n",
        "\n",
        "# Sort by score (optional)\n",
        "prediction_table = prediction_table.sort_values(\"Prediction_Score\", ascending=False)\n",
        "\n",
        "# Save\n",
        "prediction_table.to_csv(\"rf_prediction_table_default_threshold.csv\", index=False)\n",
        "\n",
        "print(\"Saved → rf_prediction_table_default_threshold.csv\")\n",
        "\n",
        "# Show first few rows\n",
        "prediction_table.head()\n"
      ],
      "metadata": {
        "id": "crZ-3IAPezBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Your top 15 proteins EXACTLY as present in your dataset\n",
        "# ----------------------------------------------------------\n",
        "top15 = [\n",
        "    \"Her2\",\"MART1\",\"PTEN\",\"NY-ESO-1\",\"CD20\",\"PR\",\"CD56\",\n",
        "    \"HLA-DR\",\"S6\",\"ER-alpha\",\"GAPDH\",\"IDO1\",\"PD-1\",\"GZMB\",\"LAG3\"\n",
        "]\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Load expression matrix + response groups\n",
        "# ----------------------------------------------------------\n",
        "expr = pd.read_csv(\"combined_expression_metadata_quantile_normalized.csv\")\n",
        "\n",
        "# Make response label\n",
        "expr['Response_Group'] = expr['radiographic_objective_response'].replace({\n",
        "    'complete response (CR)': 1,\n",
        "    'partial response (PR)': 1,\n",
        "    'progressive disease (PD)': 0,\n",
        "    'stable disease (SD)': 0\n",
        "})\n",
        "\n",
        "# Split data\n",
        "responders = expr[expr[\"Response_Group\"] == 1]\n",
        "nonresponders = expr[expr[\"Response_Group\"] == 0]\n",
        "\n",
        "results = []\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Compute differential expression for each of the 15 proteins\n",
        "# ----------------------------------------------------------\n",
        "for protein in top15:\n",
        "\n",
        "    if protein not in expr.columns:\n",
        "        print(f\"WARNING: {protein} not found in dataset\")\n",
        "        continue\n",
        "\n",
        "    r_vals = responders[protein].astype(float)\n",
        "    nr_vals = nonresponders[protein].astype(float)\n",
        "\n",
        "    # Mean expression\n",
        "    mean_r = r_vals.mean()\n",
        "    mean_nr = nr_vals.mean()\n",
        "\n",
        "    # log2 fold change\n",
        "    log2fc = np.log2((mean_r + 1e-8) / (mean_nr + 1e-8))\n",
        "\n",
        "    # Two-sample t-test\n",
        "    t_stat, p_val = ttest_ind(r_vals, nr_vals, equal_var=False)\n",
        "\n",
        "    results.append([protein, mean_r, mean_nr, log2fc, p_val])\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Adjust p-values for multiple testing\n",
        "# ----------------------------------------------------------\n",
        "results_df = pd.DataFrame(results, columns=[\"Protein\",\"Mean_R\",\"Mean_NR\",\"Log2FC\",\"p_value\"])\n",
        "results_df[\"adj_p_value\"] = multipletests(results_df[\"p_value\"], method=\"fdr_bh\")[1]\n",
        "\n",
        "# Direction\n",
        "results_df[\"Direction\"] = results_df[\"Log2FC\"].apply(\n",
        "    lambda x: \"Up in Responders\" if x > 0 else \"Up in Non-responders\"\n",
        ")\n",
        "\n",
        "print(results_df)\n",
        "\n",
        "results_df.to_csv(\"Top15_significance_test.csv\", index=False)\n",
        "print(\"\\nSaved → Top15_significance_test.csv\")\n"
      ],
      "metadata": {
        "id": "QyRI5iZOGZqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.head()"
      ],
      "metadata": {
        "id": "nNi-isGumf-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from adjustText import adjust_text\n",
        "\n",
        "# Load RF importance and get top 15 proteins\n",
        "rf_importance_df = pd.read_csv(\"RF_feature_importance_original.csv\")\n",
        "top15_proteins = rf_importance_df.head(15)['Protein'].tolist()\n",
        "\n",
        "# Thresholds\n",
        "pval_thresh = 0.05\n",
        "fc_thr = np.log2(1.2)  # 1.2-fold threshold\n",
        "\n",
        "# Mark significance using YOUR column name: \"Log2FC\"\n",
        "results_df[\"Significant\"] = results_df.apply(\n",
        "    lambda r: \"Significant\"\n",
        "    if (r[\"adj_p_value\"] < pval_thresh and abs(r[\"Log2FC\"]) >= fc_thr)\n",
        "    else \"Not significant\",\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12, 9))\n",
        "\n",
        "sns.scatterplot(\n",
        "    data=results_df,\n",
        "    x=\"Log2FC\",\n",
        "    y=-np.log10(results_df[\"adj_p_value\"]),\n",
        "    hue=\"Significant\",\n",
        "    palette={\"Significant\": \"red\", \"Not significant\": \"grey\"},\n",
        "    legend=True\n",
        ")\n",
        "\n",
        "# Threshold lines\n",
        "plt.axhline(-np.log10(pval_thresh), color='black', linestyle='--')\n",
        "plt.axvline(fc_thr, color='green', linestyle='--')\n",
        "plt.axvline(-fc_thr, color='green', linestyle='--')\n",
        "\n",
        "# Label top 15 proteins\n",
        "texts = []\n",
        "for _, row in results_df.iterrows():\n",
        "    if row[\"Protein\"] in top15_proteins:\n",
        "        texts.append(\n",
        "            plt.text(\n",
        "                row[\"Log2FC\"],\n",
        "                -np.log10(row[\"adj_p_value\"]),\n",
        "                row[\"Protein\"],\n",
        "                fontsize=9\n",
        "            )\n",
        "        )\n",
        "\n",
        "adjust_text(texts, arrowprops=dict(arrowstyle='-', color='black', lw=0.5))\n",
        "\n",
        "plt.xlabel(\"log2 Fold Change (Responder / Non-responder)\")\n",
        "plt.ylabel(\"-log10(Adjusted p-value)\")\n",
        "plt.title(\"Volcano Plot (1.2-fold cutoff, adjusted p=0.05)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"volcano_1.2fold_top15_labeled.png\", dpi=300)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9oDnmjBgl7EJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}